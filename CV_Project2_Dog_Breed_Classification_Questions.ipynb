{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Project2_Dog_Breed_Classification_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "cell_type": "markdown",
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "metadata": {
        "id": "x22THgirgsKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f251a3a1-952c-4f82-8ae0-cacd4ce13091"
      },
      "cell_type": "code",
      "source": [
        "#load libraries\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import seaborn as sns\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HBM-hf2shO6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "069763ea-f568-440e-f94a-95e71c88dd1f"
      },
      "cell_type": "code",
      "source": [
        "#establish connection\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2pdu8lD8hTyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lLAeYf6fhT9L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "cell_type": "markdown",
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = \"/content/drive/My Drive/AIML/dog_breed/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "cell_type": "markdown",
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3NHq1iBCfFjE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'test.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnUMhQrDfJmz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2G9RIxB-fOLT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hchbhMdpjfJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e866aaa-74ec-4427-8550-4d87c7230482"
      },
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  labels.csv  sample_data\tsample_submission.csv  test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sJc1lVrW_jmL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "cell_type": "markdown",
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "metadata": {
        "id": "WmlJ2VMY96IZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_df=pd.read_csv('labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPvb1RSc96If",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2c6bce90-c319-4d3f-d9a1-b141671f651d"
      },
      "cell_type": "code",
      "source": [
        "label_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "cell_type": "markdown",
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3L2naXlr96Im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2031
        },
        "outputId": "37a0214f-cb5e-4174-cf9f-8e180e956a5c"
      },
      "cell_type": "code",
      "source": [
        "label_df.groupby(['breed']).agg(['count'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>breed</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>affenpinscher</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afghan_hound</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airedale</th>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>appenzeller</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>australian_terrier</th>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basenji</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>basset</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beagle</th>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bedlington_terrier</th>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bernese_mountain_dog</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>black-and-tan_coonhound</th>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blenheim_spaniel</th>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bloodhound</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bluetick</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>border_collie</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>border_terrier</th>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>borzoi</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boston_bull</th>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bouvier_des_flandres</th>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>boxer</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brabancon_griffon</th>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>briard</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brittany_spaniel</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bull_mastiff</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cairn</th>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cardigan</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chesapeake_bay_retriever</th>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chihuahua</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rhodesian_ridgeback</th>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rottweiler</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saint_bernard</th>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>saluki</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>samoyed</th>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>schipperke</th>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scotch_terrier</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>scottish_deerhound</th>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sealyham_terrier</th>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shetland_sheepdog</th>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shih-tzu</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>siberian_husky</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>silky_terrier</th>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soft-coated_wheaten_terrier</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>staffordshire_bullterrier</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>standard_poodle</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>standard_schnauzer</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sussex_spaniel</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tibetan_mastiff</th>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tibetan_terrier</th>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toy_poodle</th>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toy_terrier</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vizsla</th>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>walker_hound</th>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weimaraner</th>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>whippet</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yorkshire_terrier</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  id\n",
              "                               count\n",
              "breed                               \n",
              "affenpinscher                     80\n",
              "afghan_hound                     116\n",
              "african_hunting_dog               86\n",
              "airedale                         107\n",
              "american_staffordshire_terrier    74\n",
              "appenzeller                       78\n",
              "australian_terrier               102\n",
              "basenji                          110\n",
              "basset                            82\n",
              "beagle                           105\n",
              "bedlington_terrier                89\n",
              "bernese_mountain_dog             114\n",
              "black-and-tan_coonhound           77\n",
              "blenheim_spaniel                 102\n",
              "bloodhound                        85\n",
              "bluetick                          85\n",
              "border_collie                     72\n",
              "border_terrier                    91\n",
              "borzoi                            75\n",
              "boston_bull                       87\n",
              "bouvier_des_flandres              86\n",
              "boxer                             75\n",
              "brabancon_griffon                 67\n",
              "briard                            66\n",
              "brittany_spaniel                  73\n",
              "bull_mastiff                      75\n",
              "cairn                            106\n",
              "cardigan                          76\n",
              "chesapeake_bay_retriever          83\n",
              "chihuahua                         71\n",
              "...                              ...\n",
              "rhodesian_ridgeback               88\n",
              "rottweiler                        76\n",
              "saint_bernard                     84\n",
              "saluki                            99\n",
              "samoyed                          109\n",
              "schipperke                        86\n",
              "scotch_terrier                    82\n",
              "scottish_deerhound               126\n",
              "sealyham_terrier                  88\n",
              "shetland_sheepdog                 76\n",
              "shih-tzu                         112\n",
              "siberian_husky                    95\n",
              "silky_terrier                     90\n",
              "soft-coated_wheaten_terrier       71\n",
              "staffordshire_bullterrier         79\n",
              "standard_poodle                   79\n",
              "standard_schnauzer                72\n",
              "sussex_spaniel                    78\n",
              "tibetan_mastiff                   69\n",
              "tibetan_terrier                  107\n",
              "toy_poodle                        80\n",
              "toy_terrier                       79\n",
              "vizsla                            70\n",
              "walker_hound                      69\n",
              "weimaraner                        85\n",
              "welsh_springer_spaniel            79\n",
              "west_highland_white_terrier       81\n",
              "whippet                           95\n",
              "wire-haired_fox_terrier           82\n",
              "yorkshire_terrier                 82\n",
              "\n",
              "[120 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "CLm3W5RN96Ir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "cell_type": "markdown",
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "metadata": {
        "id": "Q48iAcY196I3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target=pd.Series(label_df['breed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nlWmRNM96I8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot=pd.get_dummies(target,sparse=True)\n",
        "target=np.asarray(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWaJ9naXfoiU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "im_size=100 #----> image size\n",
        "ids=label_df['id']\n",
        "X_train=[]\n",
        "y_train=target\n",
        "#print(y_train[1].shape)\n",
        "\n",
        "for id in ids:\n",
        "    #img=cv2.imread('/content/drive/My Drive/AIML/dog_breed/train/{}'.format(id)+'.jpg')\n",
        "    img = cv2.imread('./train/{}.jpg'.format(id))\n",
        "    X_train.append(cv2.resize(img,(im_size,im_size)))\n",
        "    \n",
        "X_train=np.array(X_train,np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nkkZEpOe0ipk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dea5ace-8a60-4c05-de15-9195ab6f0f09"
      },
      "cell_type": "code",
      "source": [
        "#X_train = X_train[:, np.newaxis]\n",
        "\n",
        "\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 100, 100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "6ioWDEgElBOs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def standardize(array):\n",
        "    array/=255\n",
        "    return array\n",
        "X_train=standardize(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "cell_type": "markdown",
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "metadata": {
        "id": "kpWx-pgV96Jv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_x,validation_x,train_y,validation_y=train_test_split(X_train,y_train,test_size=0.3,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('sample_submission.csv')\n",
        "\n",
        "test_img=test_df['id']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DEJqZIMbm0Jo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c8a88ff-7412-40f4-87e8-4e997f7dc3c5"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "img_rows=100\n",
        "img_cols=100\n",
        "x_test_feature = []\n",
        "i = 0 # initialisation\n",
        "for f in tqdm(test_img.values): # f for format ,jpg\n",
        "    img = cv2.imread('./test/{}.jpg'.format(f))\n",
        "    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
        "    x_test_feature.append(img_resize)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10357/10357 [00:25<00:00, 406.02it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9My6qSyDnE-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "metadata": {
        "id": "93n-IntMnJGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2a99bda-c185-41d9-e22e-cf92aa7df8db"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_test_feature=np.array(x_test_feature,np.float32)\n",
        "\n",
        "\n",
        "x_test_feature.shape\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 100, 100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "O4v0jRwZ3L2N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test_feature=standardize(x_test_feature)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_tcylLbp3b_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c10a6908-9b0d-4782-e7fc-654c51108d20"
      },
      "cell_type": "code",
      "source": [
        "print (X_train.shape,x_test_feature.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10222, 100, 100, 3) (10357, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "metadata": {
        "id": "D2jxTY2S96J4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def mode_architecture():\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(32,(3,3),input_shape=X_train.shape[1:],activation='relu',padding='same'))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "    #model.add(Dropout(0.20))\n",
        "    \n",
        "    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
        "    model.add(BatchNormalization(axis=3))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    #model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6aVW2AUyxsvt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "arch_cnn=mode_architecture()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jL-BIN0MvSMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "554a6a05-d095-476c-9b07-b2f02cbe5013"
      },
      "cell_type": "code",
      "source": [
        "arch_cnn.summary()\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 100, 100, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 100, 100, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 50, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 50, 50, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 50, 50, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 25, 25, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 25, 25, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              18875392  \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 120)               0         \n",
            "=================================================================\n",
            "Total params: 19,656,504\n",
            "Trainable params: 19,656,056\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ui8EXw6_oqpR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "metadata": {
        "id": "IriIc37NozbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "aca3bfe3-465c-485a-d8f7-8ceb7d9195d9"
      },
      "cell_type": "code",
      "source": [
        "batch_size=128 #Randomly\n",
        "epochs=10  #Randomly\n",
        "print (train_x.shape,train_y.shape)\n",
        "\n",
        "val_arch=arch_cnn.fit(X_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7155, 100, 100, 3) (7155, 120)\n",
            "Epoch 1/10\n",
            "10222/10222 [==============================] - 16s 2ms/step - loss: 4.9579 - acc: 0.0141\n",
            "Epoch 2/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 4.6292 - acc: 0.0293\n",
            "Epoch 3/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 4.4040 - acc: 0.0500\n",
            "Epoch 4/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 4.1594 - acc: 0.0763\n",
            "Epoch 5/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 3.8520 - acc: 0.1079\n",
            "Epoch 6/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 3.4141 - acc: 0.1793\n",
            "Epoch 7/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 2.6704 - acc: 0.3183\n",
            "Epoch 8/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 1.6847 - acc: 0.5447\n",
            "Epoch 9/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 0.8004 - acc: 0.7811\n",
            "Epoch 10/10\n",
            "10222/10222 [==============================] - 13s 1ms/step - loss: 0.3020 - acc: 0.9187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0PR9j5_Xozmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8hWaKmjoz69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "cell_type": "markdown",
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDLQVFDP96KI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bqTlW0qHb3Xb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "arch_cnn=mode_architecture()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "cell_type": "markdown",
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "metadata": {
        "id": "sehaRgT-96KQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),steps_per_epoch=len(X_train) / 32, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "cell_type": "markdown",
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2zmLztqo5DY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "metadata": {
        "id": "rSTATrhsAo7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "metadata": {
        "id": "zy5JdbW6pIvD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "yrqs0zg7ApNw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 include_top=False, pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EItOlRBGpV_A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "metadata": {
        "id": "lQsEBgnlpHjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHpeOyW0qauW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "metadata": {
        "id": "0BpT4MLkqoaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LeQem0pHITIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "metadata": {
        "id": "C7w9CSPvIRnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kj-BwqgfIkdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "metadata": {
        "id": "YD5fAgVQIpKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "metadata": {
        "id": "SZk2SWvjIoRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}